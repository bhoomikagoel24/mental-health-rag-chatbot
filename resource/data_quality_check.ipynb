{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acbbfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✔ Dataset load kiya\n",
    "# ✔ Cleaning checks kiye\n",
    "# ✔ Data quality score nikala\n",
    "# ✔ Combined quality score nikala\n",
    "\n",
    "# Ab next step = cleaned dataset ko RAG pipeline me bhejna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65a60f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "111+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410b175b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\MentalHealth__\\\\resource'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8424df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\MentalHealth__\\resource\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "916cd08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# to get back one folder back\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691aaef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\MentalHealth__'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2ed165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b606e7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in dataset 1 : 7731\n",
      "Columns in dataset 1 : ['clean_text', 'is_depression']\n",
      "Rows in dataset 2 : 1259\n",
      "Columns in dataset 2 : ['Timestamp', 'Age', 'Gender', 'Country', 'state', 'self_employed', 'family_history', 'treatment', 'work_interfere', 'no_employees', 'remote_work', 'tech_company', 'benefits', 'care_options', 'wellness_program', 'seek_help', 'anonymity', 'leave', 'mental_health_consequence', 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview', 'mental_vs_physical', 'obs_consequence', 'comments']\n",
      "--------------------------------------------------------------------------\n",
      "clean_text       0\n",
      "is_depression    0\n",
      "dtype: int64\n",
      "Timestamp                       0\n",
      "Age                             0\n",
      "Gender                          0\n",
      "Country                         0\n",
      "state                         515\n",
      "self_employed                  18\n",
      "family_history                  0\n",
      "treatment                       0\n",
      "work_interfere                264\n",
      "no_employees                    0\n",
      "remote_work                     0\n",
      "tech_company                    0\n",
      "benefits                        0\n",
      "care_options                    0\n",
      "wellness_program                0\n",
      "seek_help                       0\n",
      "anonymity                       0\n",
      "leave                           0\n",
      "mental_health_consequence       0\n",
      "phys_health_consequence         0\n",
      "coworkers                       0\n",
      "supervisor                      0\n",
      "mental_health_interview         0\n",
      "phys_health_interview           0\n",
      "mental_vs_physical              0\n",
      "obs_consequence                 0\n",
      "comments                     1095\n",
      "dtype: int64\n",
      "--------------------------------------------------------------------------\n",
      "Duplicates in datasets 1: 81\n",
      "Duplicates in datasets 2: 0\n",
      "---------------------------------------------------------------------------\n",
      "                                          clean_text  is_depression\n",
      "0  we understand that most people who reply immed...              1\n",
      "1  welcome to r depression s check in post a plac...              1\n",
      "-------------------------------------------------------------------------\n",
      "             Timestamp  Age  Gender        Country state self_employed  \\\n",
      "0  2014-08-27 11:29:31   37  Female  United States    IL           NaN   \n",
      "1  2014-08-27 11:29:37   44       M  United States    IN           NaN   \n",
      "\n",
      "  family_history treatment work_interfere    no_employees  ...          leave  \\\n",
      "0             No       Yes          Often            6-25  ...  Somewhat easy   \n",
      "1             No        No         Rarely  More than 1000  ...     Don't know   \n",
      "\n",
      "  mental_health_consequence phys_health_consequence     coworkers supervisor  \\\n",
      "0                        No                      No  Some of them        Yes   \n",
      "1                     Maybe                      No            No         No   \n",
      "\n",
      "  mental_health_interview phys_health_interview mental_vs_physical  \\\n",
      "0                      No                 Maybe                Yes   \n",
      "1                      No                    No         Don't know   \n",
      "\n",
      "  obs_consequence comments  \n",
      "0              No      NaN  \n",
      "1              No      NaN  \n",
      "\n",
      "[2 rows x 27 columns]\n",
      "--------------------------------------------------------------------------\n",
      "count     7731.000000\n",
      "mean       361.383003\n",
      "std        695.268030\n",
      "min          3.000000\n",
      "25%         58.000000\n",
      "50%        110.000000\n",
      "75%        362.500000\n",
      "max      19822.000000\n",
      "Name: text_length, dtype: float64\n",
      "count     164.000000\n",
      "mean      243.176829\n",
      "std       331.820669\n",
      "min         1.000000\n",
      "25%        86.750000\n",
      "50%       166.500000\n",
      "75%       299.000000\n",
      "max      3548.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df1 = pd.read_csv(\"datasets/depression_dataset_reddit_cleaned.csv\")\n",
    "df2 = pd.read_csv(\"datasets/survey.csv\")\n",
    "\n",
    "# 1. Check shape\n",
    "print(f\"Rows in dataset 1 : {len(df1)}\")\n",
    "print(f\"Columns in dataset 1 : {df1.columns.tolist()}\")\n",
    "\n",
    "print(f\"Rows in dataset 2 : {len(df2)}\")\n",
    "print(f\"Columns in dataset 2 : {df2.columns.tolist()}\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "# 2. Check for nulls\n",
    "print(df1.isnull().sum())\n",
    "print(df2.isnull().sum())\n",
    "\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "# 3. Check duplicates\n",
    "print(f\"Duplicates in datasets 1: {df1.duplicated().sum()}\")\n",
    "print(f\"Duplicates in datasets 2: {df2.duplicated().sum()}\")\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "# 4.1 Sample data in dataset 1\n",
    "print(df1.head(2))\n",
    "# print(df1.sample(10))  # Random samples\n",
    "\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "# 4.2 Sample data in dataset 2\n",
    "print(df2.head(2))\n",
    "# print(df2.sample(10))  # Random samples\n",
    "\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "# 5. Text length distribution\n",
    "df1['text_length'] = df1['clean_text'].str.len()\n",
    "print(df1['text_length'].describe())\n",
    "\n",
    "# 5. Text length distribution\n",
    "df2['text_length'] = df2['comments'].str.len()\n",
    "print(df2['text_length'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99d8ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename text columns\n",
    "df1 = df1.rename(columns={'clean_text': 'text'})\n",
    "df2 = df2.rename(columns={'comments': 'text'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177f31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incomplete sentences: 7731\n",
      "Very short entries: 1536\n",
      "Non-ASCII text: 5\n",
      "Unique text entries: 7731\n"
     ]
    }
   ],
   "source": [
    "# 6. Check for incomplete sentences\n",
    "incomplete = df1[df1['text'].str.endswith('.') == False]\n",
    "print(f\"Incomplete sentences: {len(incomplete)}\")\n",
    "\n",
    "# 7. Check for very short text (likely bad quality)\n",
    "short_text = df1[df1['text'].str.len() < 50]\n",
    "print(f\"Very short entries: {len(short_text)}\")\n",
    "\n",
    "# 8. Check for special characters/encoding issues\n",
    "import re\n",
    "weird_chars = df1[df1['text'].str.contains('[^\\x00-\\x7F]+', regex=True)]\n",
    "print(f\"Non-ASCII text: {len(weird_chars)}\")\n",
    "\n",
    "# 9. Check for repetitive text\n",
    "# (Sometimes datasets have duplicate paragraphs)\n",
    "df1['text_unique'] = df1['text'].drop_duplicates()\n",
    "print(f\"Unique text entries: {len(df1['text_unique'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a87a5f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incomplete sentences: 46\n",
      "Very short entries: 26\n",
      "Non-ASCII text: 0\n",
      "Unique text entries: 1259\n"
     ]
    }
   ],
   "source": [
    "# 6. Check for incomplete sentences\n",
    "incomplete = df2[df2['text'].str.endswith('.') == False]\n",
    "print(f\"Incomplete sentences: {len(incomplete)}\")\n",
    "\n",
    "# 7. Check for very short text (likely bad quality)\n",
    "short_text = df2[df2['text'].str.len() < 50]\n",
    "print(f\"Very short entries: {len(short_text)}\")\n",
    "\n",
    "# 8. Check for special characters/encoding issues\n",
    "import re\n",
    "weird_chars = df2[df2['text'].str.contains('[^\\x00-\\x7F]+', regex=True, na=False)]\n",
    "print(f\"Non-ASCII text: {len(weird_chars)}\")\n",
    "\n",
    "# 9. Check for repetitive text\n",
    "# (Sometimes datasets have duplicate paragraphs)\n",
    "df2['text_unique'] = df2['text'].drop_duplicates()\n",
    "print(f\"Unique text entries: {len(df2['text_unique'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e0ca5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality_score(df, text_column):\n",
    "    \"\"\"\n",
    "    Returns quality score 0-100\n",
    "    \"\"\"\n",
    "    score = 100\n",
    "    \n",
    "    # Penalize nulls\n",
    "    null_pct = df[text_column].isnull().sum() / len(df)\n",
    "    score -= null_pct * 30\n",
    "    \n",
    "    # Penalize duplicates\n",
    "    dup_pct = df.duplicated().sum() / len(df)\n",
    "    score -= dup_pct * 20\n",
    "    \n",
    "    # Penalize very short text\n",
    "    short_pct = (df[text_column].str.len() < 100).sum() / len(df)\n",
    "    score -= short_pct * 20\n",
    "    \n",
    "    # Penalize incomplete sentences\n",
    "    incomplete_pct = (df[text_column].str.endswith('.') == False).sum() / len(df)\n",
    "    score -= incomplete_pct * 10\n",
    "    \n",
    "    return max(0, score)\n",
    "\n",
    "def quality_rating(score):\n",
    "    \"\"\"Return star rating label.\"\"\"\n",
    "    if score >= 90:\n",
    "        return \"⭐⭐⭐⭐⭐ Excellent\"\n",
    "    elif score >= 80:\n",
    "        return \"⭐⭐⭐⭐ Very Good\"\n",
    "    elif score >= 70:\n",
    "        return \"⭐⭐⭐ Good\"\n",
    "    elif score >= 60:\n",
    "        return \"⭐⭐ Fair\"\n",
    "    else:\n",
    "        return \"⭐ Poor\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db122988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Score: 80.5833656706765/100\n",
      "----------------------------------------------------------------\n",
      "Data Quality Score: 72.76409849086576/100\n"
     ]
    }
   ],
   "source": [
    "quality1 = data_quality_score(df1, 'text')\n",
    "print(f\"Data Quality Score: {quality1}/100\")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "quality2 = data_quality_score(df2, 'text')\n",
    "print(f\"Data Quality Score: {quality2}/100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ed53712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined Dataset Quality Score: 79.48832035595105/100\n",
      "Combined Rating: ⭐⭐⭐ Good\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# COMBINED SCORE + RATING\n",
    "# -----------------------------\n",
    "\n",
    "# Combine both datasets for overall score\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "combined_quality = data_quality_score(combined_df, \"text\")\n",
    "combined_rating = quality_rating(combined_quality)\n",
    "\n",
    "print(f\"\\nCombined Dataset Quality Score: {combined_quality}/100\")\n",
    "print(f\"Combined Rating: {combined_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2839f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc9b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
